# PRODIGY_ML_02 - Hand Gesture Recognition

## 📌 Task
Develop a hand gesture recognition model that can accurately identify and classify different hand gestures from image or video data, enabling intuitive human-computer interaction and gesture-based control systems.

## 📁 Dataset
We used the [LeapGestRecog](https://www.kaggle.com/datasets/gti-upm/leapgestrecog) dataset from Kaggle, which contains thousands of grayscale gesture images divided into training and test sets across multiple gesture classes.

## ✅ Objectives
- Build a robust hand gesture recognition model using Machine Learning.
- Classify hand gestures from static images or real-time video.
- Enable gesture-based control for interactive systems.
- Ensure high accuracy and generalization on unseen data.

## 🧠 Algorithms & Techniques Used
- **Data Preprocessing**: Grayscale image normalization, resizing, and label encoding.
- **Modeling Techniques**:  
  - Convolutional Neural Networks (CNN) for image classification.  
  - OpenCV for image/video frame capturing and processing.
- **Evaluation Metrics**: Accuracy, confusion matrix.

## 🛠️ Tools & Libraries
- Python
- NumPy
- OpenCV
- TensorFlow / Keras
- Matplotlib
- scikit-learn

## 📊 Results
- Achieved high classification accuracy on test data.
- Successfully implemented real-time hand gesture detection using webcam.
- Demonstrated gesture-based interaction with the system.




